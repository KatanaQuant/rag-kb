version: '3.8'

services:
  rag-api:
    build:
      context: ./api
      dockerfile: Dockerfile
      # Enable BuildKit for faster builds (requires DOCKER_BUILDKIT=1)
      cache_from:
        - rag-api:latest
    image: rag-api:latest  # Tag the built image for cache_from to work
    container_name: rag-api
    ports:
      - "${RAG_PORT:-8000}:8000"
    volumes:
      - ./knowledge_base:/app/knowledge_base
      - ./data:/app/data
      - ./tests:/app/tests  # Mount tests directory for test execution
      - ./api/ingestion:/app/ingestion  # Dev mount for ingestion modules
      - ./api/operations:/app/operations  # Dev mount for API operations (query, list, search)
      - ./api/routes:/app/routes  # Dev mount for route handlers
      - ./api/pipeline:/app/pipeline  # Dev mount for pipeline services (embedding, queue, workers)
      - ./api/startup:/app/startup  # Dev mount for startup services
      - ./api/main.py:/app/main.py  # Dev mount for main.py changes
      - ./api/config.py:/app/config.py  # Config file
      - ./api/environment_config_loader.py:/app/environment_config_loader.py  # Environment loader
      - ./api/migrations:/app/migrations  # Migration scripts
      - ./config:/app/yara_config  # Mount config directory for YARA rules
      - ./.cache/deepsearch_glm:/app/.cache/deepsearch_glm  # DeepSearch GLM cache
      - ./.cache/docling:/home/appuser/.cache/docling  # Docling model cache
      - ./.cache/huggingface:/home/appuser/.cache/huggingface  # Hugging Face model cache (Docling models)
      - ./.cache/easyocr:/home/appuser/.EasyOCR  # EasyOCR model cache (detection models)
      - ./.cache/rapidocr:/opt/venv/lib/python3.13/site-packages/rapidocr/models  # RapidOCR model cache (OCR models)
      - ./.cache/clamav:/var/lib/clamav  # ClamAV virus database cache (persists ~230MB signatures)
    environment:
      - PYTHONUNBUFFERED=1
      - MODEL_NAME=${MODEL_NAME:-Snowflake/snowflake-arctic-embed-l-v2.0}
      - BATCH_SIZE=${BATCH_SIZE:-5}
      - BATCH_DELAY=${BATCH_DELAY:-0.5}
      - USE_DOCLING=${USE_DOCLING:-true}  # Enable Docling PDF extraction (default)
      - SEMANTIC_CHUNKING=${SEMANTIC_CHUNKING:-true}  # Enable semantic chunking (default)
      - CHUNK_MAX_TOKENS=${CHUNK_MAX_TOKENS:-512}  # Max tokens per semantic chunk
      - AUTO_REPAIR_ORPHANS=${AUTO_REPAIR_ORPHANS:-true}  # Auto-repair orphaned files on startup
      - CHUNK_WORKERS=${CHUNK_WORKERS:-1}  # Concurrent chunking threads
      - EMBEDDING_WORKERS=${EMBEDDING_WORKERS:-2}  # Concurrent embedding threads (2 for CPU, increase for GPU)
      - MAX_PENDING_EMBEDDINGS=${MAX_PENDING_EMBEDDINGS:-6}  # Max queued embeddings before throttling
      - OMP_NUM_THREADS=2  # Limit OpenMP threads to prevent deadlock
      - MKL_NUM_THREADS=2  # Limit MKL threads
      - OPENBLAS_NUM_THREADS=2  # Limit OpenBLAS threads
      - NUMEXPR_NUM_THREADS=2  # Limit NumExpr threads
    restart: unless-stopped
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8000/health"]
      interval: 30s
      timeout: 10s
      retries: 3
    deploy:
      resources:
        limits:
          cpus: '${MAX_CPUS:-12.8}'
          memory: ${MAX_MEMORY:-24G}
