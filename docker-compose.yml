version: '3.8'

services:
  rag-api:
    build:
      context: ./api
      dockerfile: Dockerfile
      # Enable BuildKit for faster builds (requires DOCKER_BUILDKIT=1)
      cache_from:
        - rag-api:latest
    image: rag-api:latest  # Tag the built image for cache_from to work
    container_name: rag-api
    ports:
      - "${RAG_PORT:-8000}:8000"
    volumes:
      - ./knowledge_base:/app/knowledge_base
      - ./data:/app/data
      - ./tests:/app/tests  # Mount tests directory for test execution
      # HOT RELOAD DISABLED (production config)
      # Uncomment for development:
      # - ./api/ingestion:/app/ingestion
      # - ./api/operations:/app/operations
      # - ./api/routes:/app/routes
      # - ./api/pipeline:/app/pipeline
      # - ./api/startup:/app/startup
      # - ./api/main.py:/app/main.py
      # - ./api/config.py:/app/config.py
      # - ./api/environment_config_loader.py:/app/environment_config_loader.py
      - ./api/migrations:/app/migrations  # Migration scripts
      - ./config:/app/yara_config  # Mount config directory for YARA rules
      - ./.cache/deepsearch_glm:/app/.cache/deepsearch_glm  # DeepSearch GLM cache
      - ./.cache/docling:/home/appuser/.cache/docling  # Docling model cache
      - ./.cache/huggingface:/home/appuser/.cache/huggingface  # Hugging Face model cache (Docling models)
      - ./.cache/easyocr:/home/appuser/.EasyOCR  # EasyOCR model cache (detection models)
      - ./.cache/rapidocr:/opt/venv/lib/python3.13/site-packages/rapidocr/models  # RapidOCR model cache (OCR models)
      - ./.cache/clamav:/var/lib/clamav  # ClamAV virus database cache (persists ~230MB signatures)
    environment:
      - PYTHONUNBUFFERED=1
      - MODEL_NAME=${MODEL_NAME:-Snowflake/snowflake-arctic-embed-l-v2.0}
      - BATCH_SIZE=${BATCH_SIZE:-5}
      - BATCH_DELAY=${BATCH_DELAY:-0.5}
      - USE_DOCLING=${USE_DOCLING:-true}  # Enable Docling PDF extraction (default)
      - SEMANTIC_CHUNKING=${SEMANTIC_CHUNKING:-true}  # Enable semantic chunking (default)
      - CHUNK_MAX_TOKENS=${CHUNK_MAX_TOKENS:-512}  # Max tokens per semantic chunk
      - AUTO_REPAIR_ORPHANS=${AUTO_REPAIR_ORPHANS:-true}  # Auto-repair orphaned files on startup
      - CHUNK_WORKERS=${CHUNK_WORKERS:-1}  # Concurrent chunking threads (1 for Balanced profile)
      - EMBEDDING_WORKERS=${EMBEDDING_WORKERS:-2}  # Concurrent embedding threads (2 optimal for GIL)
      - EMBEDDING_BATCH_SIZE=${EMBEDDING_BATCH_SIZE:-32}  # Chunks per batch for embedding (32 optimal for CPU)
      - MAX_PENDING_EMBEDDINGS=${MAX_PENDING_EMBEDDINGS:-6}  # Max queued embeddings before throttling
      - OMP_NUM_THREADS=${OMP_NUM_THREADS:-2}  # OpenMP threads per worker
      - MKL_NUM_THREADS=${MKL_NUM_THREADS:-2}  # MKL threads
      - OPENBLAS_NUM_THREADS=${OMP_NUM_THREADS:-2}  # OpenBLAS threads (follows OMP)
      - NUMEXPR_NUM_THREADS=${OMP_NUM_THREADS:-2}  # NumExpr threads (follows OMP)
    restart: unless-stopped
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8000/health"]
      interval: 30s
      timeout: 10s
      retries: 3
    deploy:
      resources:
        limits:
          cpus: '${MAX_CPUS:-4.0}'
          memory: ${MAX_MEMORY:-8G}
