# Release v2.2.0-beta

**Date**: 2025-12-04
**Type**: Beta Pre-release
**Breaking Changes**: No (but migration required for existing users)

---

## Summary

Performance and intelligence release: 200x faster vector search with persistent HNSW index, plus agentic query features for improved search relevance.

### Highlights

- **Vectorlite HNSW**: ~10ms queries (was ~2s), persistent index survives restarts
- **Query Decomposition v2**: +5.6% relevance for compound queries
- **Follow-up Suggestions**: Related query recommendations
- **Confidence Scores**: Reranker scores exposed in API

---

## Migration Guide

### From v2.1.5-beta

**Required**: Run the migration script to convert sqlite-vec to vectorlite format.

#### 1. Stop Services

```bash
docker-compose down
```

#### 2. Backup Database (Recommended)

```bash
cp data/rag.db data/rag.db.backup-$(date +%Y%m%d)
```

#### 3. Update and Rebuild

```bash
git fetch --tags
git checkout v2.2.0-beta
docker-compose build --no-cache
docker-compose up -d
```

#### 4. Run Migration Script

```bash
docker exec rag-api python /app/ingestion/vector_migration.py /app/data/rag.db 1024
```

Expected output:
```
Found 59086 vectors to migrate
Reading existing embeddings...
Loaded 59086 embeddings into memory
Dropping old vec_chunks table...
Creating vectorlite table (dim=1024, index=/app/data/vec_chunks.idx)...
Inserting 59086 embeddings...
  Progress: 59086/59086 (100%)

Migration complete: {'vectors_migrated': 59086, 'success': True, 'duration_seconds': 78.2}

Verifying...
Verification: {'valid': True, 'test_results': 5, 'chunk_count': 59086}
```

#### 5. Verify Migration

```bash
# Check health
curl http://localhost:8000/health

# Test query (should be fast: <100ms)
curl -X POST http://localhost:8000/query \
  -H "Content-Type: application/json" \
  -d '{"text": "test query", "top_k": 3}'
```

### New Installations

New installations automatically create vectorlite tables. No migration needed.

---

## Performance Improvements

### Vector Search: 200x Faster

| Metric | Before (sqlite-vec) | After (vectorlite) | Improvement |
|--------|--------------------|--------------------|-------------|
| Query time | ~2,000ms | ~10ms | **200x faster** |
| Startup | 42s | ~1s | **42x faster** |
| Memory | 250MB index | ~0MB | **Eliminated** |
| Persistence | In-memory only | Disk | **Survives restart** |

### Benchmark Results

**Test Environment**:
- Machine: 16 cores, 30GB RAM (70% allocation: 11 CPUs, 21GB)
- Dataset: 59,086 vectors (1024 dimensions, Snowflake Arctic embeddings)
- Query: "What is technical debt and how to manage it?"

#### Version Comparison

| Configuration | Index Type | Startup | Query Time | vs Baseline |
|---------------|------------|---------|------------|-------------|
| v1.7.11 | sqlite-vec (brute-force) | 21s | **20.5s** | baseline |
| v2.1.x | NumPy in-memory | 42s | **2.0s** | 10x faster |
| **v2.2.0-beta** | **vectorlite HNSW** | **~1s** | **~10ms** | **2000x faster** |

#### Component Breakdown

| Component | Time | Complexity | Notes |
|-----------|------|------------|-------|
| sqlite-vec brute-force | ~20s | O(n) | Full scan, unusable at scale |
| NumPy vectorized search | ~2s | O(n) | 10x faster, but 42s startup + 250MB RAM |
| **vectorlite HNSW** | **~10ms** | **O(log n)** | Persistent index, no RAM overhead |
| Reranking (CPU, warm) | ~19s | O(k) | Cross-encoder on top-k results |

#### Full Configuration Matrix

| Config | Index | Rerank | Startup | Query | Notes |
|--------|-------|--------|---------|-------|-------|
| sqlite-vec | brute-force | OFF | 21s | 20.5s | v1.7.11 baseline |
| sqlite-vec | brute-force | ON | 44s | 56.2s | 2.7x slower |
| NumPy | in-memory | OFF | 42s | 2.0s | v2.1.x workaround |
| NumPy | in-memory | ON | 44s | 39.8s | Best quality, slow |
| **vectorlite** | **HNSW disk** | **OFF** | **~1s** | **~10ms** | **Recommended** |
| vectorlite | HNSW disk | ON | ~1s | ~19s | GPU recommended |

---

## API Changes

### Request: New `decompose` Parameter

```json
{
  "text": "position sizing vs risk management",
  "top_k": 5,
  "threshold": 0.5,
  "decompose": true
}
```

| Parameter | Type | Default | Description |
|-----------|------|---------|-------------|
| `text` | string | required | Search query |
| `top_k` | int | 5 | Number of results |
| `threshold` | float | 0.0 | Minimum similarity score |
| `decompose` | bool | **true** | Auto-decompose compound queries |

### Response: New Fields

```json
{
  "query": "position sizing vs risk management",
  "total_results": 5,
  "results": [
    {
      "content": "Position sizing determines how much...",
      "source": "books/trading-guide.pdf",
      "page": 42,
      "score": 0.89,
      "rerank_score": 0.92,
      "metadata": {}
    }
  ],
  "suggestions": [
    "What is the Kelly criterion for position sizing?",
    "How to calculate value at risk?"
  ],
  "decomposition": {
    "applied": true,
    "sub_queries": ["position sizing", "risk management"]
  }
}
```

| Field | Type | Description |
|-------|------|-------------|
| `results[].rerank_score` | float | Cross-encoder score when reranking enabled |
| `suggestions` | array | Follow-up query recommendations |
| `decomposition.applied` | bool | Whether query was decomposed |
| `decomposition.sub_queries` | array | Detected sub-queries |

---

## Query Decomposition (v2)

### How It Works

When `decompose=true` (default), the API detects compound queries:

| Pattern | Example | Sub-queries |
|---------|---------|-------------|
| Conjunctions | "X and Y" | ["X", "Y"] |
| Comparisons | "X vs Y", "compare X with Y" | ["X", "Y"] |
| Multiple questions | "What is X? How does Y?" | ["What is X", "How does Y"] |

For compound queries:
1. Each sub-query is searched independently
2. Results are merged and deduplicated
3. Sorted by score, top_k returned
4. If reranking enabled, merged results reranked against original query

### Benchmark Results

**Aggregate Results** (5 compound queries):

| Config | Avg Score | Top Score | Total Time | Per Query |
|--------|-----------|-----------|------------|-----------|
| Without decomposition | 0.579 | 0.603 | 930ms | 186ms |
| With decomposition (v2) | 0.589 | 0.637 | 1685ms | 337ms |
| **Improvement** | **+1.7%** | **+5.6%** | +81% | +151ms |

**Per-Query Breakdown**:

| Query | Without (ms) | With (ms) | Overhead |
|-------|--------------|-----------|----------|
| "What is technical debt and how to manage it?" | 181 | 378 | +197ms |
| "Position sizing vs risk management" | 184 | 302 | +118ms |
| "Compare momentum and mean reversion strategies" | 191 | 364 | +173ms |
| "Explain refactoring and when to use it" | 192 | 325 | +133ms |
| "Dependency injection vs service locator pattern" | 182 | 315 | +133ms |

**Qualitative Analysis**:

*"Position sizing vs risk management"*:
- Without decomposition: Results dominated by AFTS trading posts
- With decomposition: Gets dedicated risk management AND position sizing content
- **Better topical coverage**

*"What is technical debt and how to manage it?"*:
- Without decomposition: Mostly trading books (semantic mismatch)
- With decomposition: Found "Naming Things" which discusses technical topics
- **Decomposition helps with mixed-content knowledge bases**

### When to Disable

Set `decompose=false` when:
- "and"/"or" are part of the search term (e.g., "Romeo and Juliet")
- You need deterministic results
- Latency is critical

---

## Follow-up Suggestions

The API now returns related query suggestions based on result content:

```json
{
  "suggestions": [
    "What is the Kelly criterion for position sizing?",
    "How to calculate value at risk?",
    "Explain stop-loss strategies"
  ]
}
```

Suggestions are generated by analyzing:
- Topics covered in search results
- Related concepts in the knowledge base
- Query patterns that lead to high-quality results

---

## Files Changed

### Added
- `api/ingestion/vector_migration.py` - sqlite-vec to vectorlite migration
- `api/ingestion/numpy_vector_index.py` - NumPy fallback (deprecated)
- `tests/test_vector_migration.py` - Migration integration tests
- `tests/test_query_enhancements.py` - Decomposition tests
- `scripts/benchmark_agentic.py` - Agentic features benchmark
- `scripts/benchmark_queries.py` - Query performance benchmark

### Modified
- `api/models.py` - QueryRequest, QueryResponse, DecompositionInfo models
- `api/operations/query_executor.py` - v2 sub-query execution
- `api/query_cache.py` - Cache key includes `decompose` param
- `api/ingestion/database.py` - Vectorlite support (sync layer)
- `api/ingestion/chunk_repository.py` - Vectorlite insert syntax
- `api/ingestion/search_repository.py` - knn_search queries
- `api/ingestion/async_*.py` - Async layer vectorlite support
- `docs/API.md` - New parameters and response fields
- `docs/PIPELINE.md` - Vectorlite architecture
- `docs/CONFIGURATION.md` - New config options

### Deprecated
- `api/ingestion/numpy_vector_index.py` - Replaced by vectorlite (can be removed in v2.3.0)

---

## Bug Fixes

### Sync VectorStore Migration
The synchronous database layer was still using sqlite-vec syntax after the async layer was migrated. This caused new file indexing to fail. Fixed by updating:
- `DatabaseConnection` to load vectorlite extension
- `SchemaManager` to use vectorlite table syntax
- `VectorChunkRepository` to use `rowid` instead of `chunk_id`

### Cache Key Mismatch
Queries with `decompose=true` and `decompose=false` were sharing cache entries, causing incorrect results. Fixed by including `decompose` parameter in cache key.

---

## Compatibility

| Component | v2.1.5-beta | v2.2.0-beta |
|-----------|-------------|-------------|
| Database schema | sqlite-vec | **vectorlite** (migration required) |
| Index file | None | `data/vec_chunks.idx` (240MB) |
| API endpoints | Unchanged | Unchanged (new optional params) |
| Query params | `text`, `top_k`, `threshold` | + `decompose` |
| Response fields | `results`, `query`, `total_results` | + `suggestions`, `decomposition`, `rerank_score` |

---

## Known Limitations

### Reranking on CPU
Reranking adds ~20s per query on CPU. Only viable with GPU acceleration.

| Config | Search | Rerank | Total |
|--------|--------|--------|-------|
| vectorlite only | 10ms | 0 | 10ms |
| vectorlite + rerank (CPU) | 10ms | ~20s | ~20s |

Recommendation: Disable reranking on CPU deployments.

### Decomposition Patterns
Current decomposition uses regex patterns. Complex queries may not decompose correctly:
- Supported: "X and Y", "X vs Y", "compare X with Y"
- Not supported: "explain the relationship between X and Y"

Future: LLM-based decomposition for complex queries.

---

## Testing

This beta has passed:
- Unit tests: 888+ passing
- Migration tests: 7 passing (new)
- Query enhancement tests: passing (new)
- E2E filetype tests: .py, .go, .ipynb, .pdf, .epub
- EICAR malware detection: quarantined correctly
- Performance benchmarks: 200x improvement verified

---

## Rollback

If you need to rollback to v2.1.5-beta:

```bash
# Stop services
docker-compose down

# Restore backup
cp data/rag.db.backup-YYYYMMDD data/rag.db
rm data/vec_chunks.idx

# Checkout previous version
git checkout v2.1.5-beta
docker-compose build --no-cache
docker-compose up -d
```

Note: Rollback requires restoring the pre-migration database backup.

---

## Upgrade Path

```
v1.9.1 → v2.1.5-beta → v2.2.0-beta
         (kb/ rename)   (vectorlite migration)
```

If upgrading from v1.9.1, follow both migration guides:
1. [v2.1.5-beta Migration](v2.1.5-beta.md) - Directory rename
2. This guide - Vectorlite migration

---

Report issues at: https://github.com/KatanaQuant/rag-kb/issues
