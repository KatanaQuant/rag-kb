# v2.3.0-beta Release Notes

**Release Date**: 2025-12-08
**Previous Stable**: v2.2.4-beta

---

## Overview

This release migrates the entire database layer from SQLite + vectorlite to PostgreSQL + pgvector, providing full ACID compliance and eliminating all index file management complexity.

**Key improvements:**
- Full ACID compliance with PostgreSQL WAL
- Automatic crash recovery (no more manual rebuild-hnsw)
- Native PostgreSQL full-text search (tsvector replaces FTS5)
- ~300 lines of code deleted (no periodic flush, no index file management)
- Linux ARM64 support for Mac Docker users

---

## Highlights

| Feature | Before (v2.2.4) | After (v2.3.0) |
|---------|-----------------|----------------|
| Vector storage | vectorlite HNSW + .idx file | pgvector HNSW in PostgreSQL |
| Full-text search | SQLite FTS5 | PostgreSQL tsvector + GIN |
| ACID compliance | None | Full PostgreSQL WAL |
| Crash recovery | Manual rebuild-hnsw | Automatic |
| Periodic flush | Every 5 minutes | Not needed |
| Index file management | vec_chunks.idx (218MB) | Not needed |
| Linux ARM64 | Not supported | Fully supported |

---

## Breaking Changes

### Database Migration Required

v2.3.0-beta uses PostgreSQL instead of SQLite. You must run the migration script to move your data.

**CRITICAL: Pause Indexing Before Migration**

Before migrating, you MUST pause the indexing queue to prevent the file watcher from polluting data during migration:

```bash
# 1. PAUSE INDEXING FIRST (critical!)
curl -X POST http://localhost:8000/indexing/pause

# 2. Wait for active jobs to complete
curl http://localhost:8000/queue/jobs | jq '.active_jobs'
# Repeat until all active_jobs show null

# 3. Now stop containers
docker-compose down
```

**IMPORTANT**: The migration script requires `vectorlite-py` installed on your HOST machine to read the existing HNSW embeddings. This is a one-time requirement for migration only.

```bash
# 4. (continued from above) Stop current containers
docker-compose down

# 5. Get v2.3.0-beta
git fetch --tags
git checkout v2.3.0-beta

# 3. Install vectorlite-py on HOST (required to read existing embeddings)
pip install vectorlite-py

# 4. Start ONLY PostgreSQL first
docker-compose up -d postgres
sleep 10  # Wait for PostgreSQL to initialize

# 5. Run migration (reads SQLite + vectorlite, writes to PostgreSQL)
python scripts/migrate_to_postgres.py

# Expected output:
#   Migrated 1634 documents
#   Migrated 51542 chunks
#   Read 51560 vectors via knn_search
#   Migrated 51361 vectors
#   ...

# 6. Rebuild FTS entries (tsvector from chunk content)
docker exec rag-kb-postgres psql -U ragkb -d ragkb -c "
INSERT INTO fts_chunks (chunk_id, content)
SELECT id, content FROM chunks
ON CONFLICT (chunk_id) DO NOTHING;
"

# 7. Start full stack
docker-compose up -d

# 8. Verify
curl http://localhost:8000/health
curl http://localhost:8000/api/maintenance/verify-integrity | jq
```

**What gets migrated:**
| Data | Source | Target |
|------|--------|--------|
| Documents | `documents` table | PostgreSQL `documents` |
| Chunks | `chunks` table | PostgreSQL `chunks` |
| Embeddings | `vec_chunks` (vectorlite HNSW) | PostgreSQL `vec_chunks` (pgvector) |
| FTS | SQLite FTS5 | PostgreSQL `fts_chunks` (tsvector) |
| Graph | `graph_nodes`, `graph_edges` | PostgreSQL graph tables |
| Progress | `processing_progress` | PostgreSQL `processing_progress` |
| Security cache | `security_scan_cache` | PostgreSQL `security_scan_cache` |

### Docker Compose Changes

The stack now includes a PostgreSQL service:

```yaml
services:
  postgres:
    image: pgvector/pgvector:pg16
    container_name: rag-kb-postgres
    environment:
      POSTGRES_USER: ragkb
      POSTGRES_PASSWORD: ragkb
      POSTGRES_DB: ragkb
    volumes:
      - rag_kb_postgres_data:/var/lib/postgresql/data
    ports:
      - "5432:5432"

  rag-api:
    depends_on:
      postgres:
        condition: service_healthy
    environment:
      DATABASE_URL: postgresql://ragkb:ragkb@postgres:5432/ragkb
```

---

## What's New

### PostgreSQL Backup & Restore Scripts

New scripts for easy data portability and disaster recovery:

- **`scripts/backup_postgres.sh`** - Export database to `data/ragkb_backup.sql`
  - Optional compression: `--compress` flag (80-90% size reduction)
  - Works with all data: documents, chunks, embeddings, FTS indexes

- **`scripts/restore_postgres.sh`** - Import database on fresh install or existing instance
  - Full replace mode: Uses pg_dump's `--clean` flag (DROP + CREATE)
  - Works for fresh installs and migrations (replaces existing data)
  - Enables multi-machine workflows and disaster recovery

**Example workflow:**
```bash
# Backup on source machine
./scripts/backup_postgres.sh --compress

# Transfer to new machine
scp data/ragkb_backup.sql.gz user@new-machine:/path/to/rag-kb/data/

# Restore on destination (start PostgreSQL first, then import, then full stack)
docker-compose build --no-cache  # If first time on new machine
docker-compose up -d postgres
sleep 10  # Wait for PostgreSQL to initialize
./scripts/restore_postgres.sh data/ragkb_backup.sql.gz
docker-compose up -d
curl -X POST http://localhost:8000/indexing/pause  # Prevent re-indexing
```

See [MAINTENANCE.md - Backup & Restore](../MAINTENANCE.md#backup--restore) for complete guide.

### PostgreSQL + pgvector

All data now lives in PostgreSQL:

| Table | Purpose |
|-------|---------|
| documents | Document metadata |
| chunks | Text chunks with content |
| vec_chunks | Embeddings with HNSW index |
| fts_chunks | Full-text search with tsvector |
| graph_nodes / graph_edges | Knowledge graph |
| processing_progress | Indexing progress |
| security_scan_cache | ClamAV/YARA scan results |

### HNSW Index Configuration

```sql
CREATE INDEX idx_vec_chunks_hnsw ON vec_chunks
USING hnsw (embedding vector_cosine_ops)
WITH (m=16, ef_construction=200);
```

Search uses `ef_search=150` for ~95% recall, matching v2.2.4-beta accuracy.

### Full-Text Search

PostgreSQL tsvector replaces SQLite FTS5:

```sql
-- Automatic tsvector generation
CREATE TABLE fts_chunks (
    chunk_id INTEGER PRIMARY KEY REFERENCES chunks(id) ON DELETE CASCADE,
    content TEXT,
    tsv tsvector GENERATED ALWAYS AS (to_tsvector('english', content)) STORED
);
CREATE INDEX idx_fts_chunks_tsv ON fts_chunks USING GIN(tsv);
```

### Simplified Architecture

Code deleted:
- `VectorStore._start_periodic_flush()` - ACID handles durability
- `VectorStore._stop_periodic_flush()` - No more timers
- `VectorStore._flush_hnsw_index()` - Commits are automatic
- Index file validation logic
- Connection cycling for persistence

---

## Architecture

### New Files

| File | Purpose |
|------|---------|
| `api/ingestion/postgres_connection.py` | PostgreSQL connection wrapper |
| `api/ingestion/postgres_database.py` | PostgresVectorStore facade |
| `api/ingestion/postgres_repositories.py` | All PostgreSQL repositories |
| `api/ingestion/postgres_progress.py` | Progress tracking in PostgreSQL |
| `api/ingestion/async_postgres.py` | Async repositories (asyncpg) |
| `api/operations/postgres_maintenance.py` | Maintenance utilities |
| `api/pipeline/postgres_security_cache.py` | Security scan caching |
| `scripts/migrate_to_postgres.py` | Migration script |

### Dependencies Added

```
psycopg2-binary>=2.9.9
asyncpg>=0.29.0
```

---

## Migration Guide

### Fresh Install

```bash
git clone https://github.com/KatanaQuant/rag-kb.git
cd rag-kb
docker-compose up -d
```

PostgreSQL will initialize automatically. Add files to `kb/` to start indexing.

### Upgrading from v2.2.x (SQLite + vectorlite)

**Prerequisites:**
- Python 3.8+ on host
- `pip install vectorlite-py psycopg2-binary` on host
- Existing `data/rag.db` and `data/vec_chunks.idx` files

```bash
# 1. Backup your SQLite database and HNSW index
cp data/rag.db data/rag.db.backup
cp data/vec_chunks.idx data/vec_chunks.idx.backup

# 2. Stop containers completely
docker-compose down

# 3. Get v2.3.0
git fetch --tags
git checkout v2.3.0

# 4. Install migration dependencies on HOST
pip install vectorlite-py psycopg2-binary

# 5. Rebuild API container (includes psycopg2)
docker-compose build --no-cache rag-api

# 6. Start PostgreSQL first (creates empty database)
docker-compose up -d postgres
sleep 15  # Wait for init

# 7. Run migration script
python scripts/migrate_to_postgres.py

# 8. Rebuild FTS (FTS5 can't be migrated directly)
docker exec rag-kb-postgres psql -U ragkb -d ragkb -c "
INSERT INTO fts_chunks (chunk_id, content)
SELECT id, content FROM chunks
ON CONFLICT (chunk_id) DO NOTHING;
"

# 9. Start full stack
docker-compose up -d

# 10. Verify migration
curl -s http://localhost:8000/health | jq
curl -s http://localhost:8000/api/maintenance/verify-integrity | jq

# Expected: documents, chunks, vec_chunks counts should match your data
```

**Troubleshooting v2.2.x migration:**

| Issue | Solution |
|-------|----------|
| `no such module: vectorlite` | Install vectorlite-py on HOST: `pip install vectorlite-py` |
| `no query solution` | The HNSW index path is wrong - script auto-fixes this |
| `vec_chunks: 0 rows` | vectorlite not finding index file - check `data/vec_chunks.idx` exists |
| `connection refused` | PostgreSQL not ready - wait longer or check `docker logs rag-kb-postgres` |

### Upgrading from v1.9.x (pre-vectorlite)

v1.9.x used a different database schema. You have two options:

**Option A: Two-step migration (recommended)**
1. First upgrade to v2.2.4-beta (regenerates embeddings with vectorlite)
2. Then upgrade to v2.3.0 (migrates to PostgreSQL)

```bash
# Step 1: Upgrade to v2.2.4-beta first
git checkout v2.2.4-beta
docker-compose down
docker-compose build --no-cache
docker-compose up -d
# Wait for re-indexing to complete (check /indexing/status)

# Step 2: Then follow "Upgrading from v2.2.x" above
```

**Option B: Fresh start (faster if you have small KB)**
1. Backup your `kb/` directory (your source files)
2. Delete `data/` directory
3. Install v2.3.0 fresh
4. Let it re-index everything

```bash
# Backup source files only
cp -r kb/ kb_backup/

# Clean slate
rm -rf data/
git checkout v2.3.0
docker-compose down
docker-compose build --no-cache
docker-compose up -d

# Files in kb/ will be re-indexed automatically
```

### Fresh Install (no existing data)

No migration needed - just start the stack:

```bash
git clone https://github.com/KatanaQuant/rag-kb.git
cd rag-kb
docker-compose up -d

# Add files to kb/ directory to start indexing
```

PostgreSQL initializes automatically with empty tables.

---

## Configuration

### Environment Variables

| Variable | Default | Purpose |
|----------|---------|---------|
| DATABASE_URL | postgresql://ragkb:ragkb@postgres:5432/ragkb | PostgreSQL connection |
| HNSW_EF_SEARCH | 150 | Search recall (~95%) |
| HYBRID_SEARCH_ENABLED | true | Vector + keyword search |
| TITLE_BOOST_ENABLED | true | Filename matching |

### PostgreSQL Tuning (Optional)

For large knowledge bases (100k+ documents):

```yaml
postgres:
  environment:
    POSTGRES_SHARED_BUFFERS: 256MB
    POSTGRES_EFFECTIVE_CACHE_SIZE: 1GB
    POSTGRES_WORK_MEM: 64MB
```

---

## Known Limitations

| Limitation | Impact | Notes |
|------------|--------|-------|
| Code file queries | 33% accuracy for .py/.ipynb | Contextual embeddings planned |
| Requires Docker | PostgreSQL runs in container | No standalone mode |

---

## Troubleshooting

### PostgreSQL won't start

```bash
# Check logs
docker-compose logs postgres

# If port conflict
docker-compose down
# Edit docker-compose.yml to change port 5432
docker-compose up -d
```

### Migration fails

```bash
# Check SQLite database exists
ls -la data/rag.db

# Run with verbose output
python scripts/migrate_to_postgres.py --verbose
```

### Search returns 0 results after migration

```bash
# Check vector count
curl http://localhost:8000/api/maintenance/verify-integrity | jq

# If vec_chunks count is 0, re-run migration
python scripts/migrate_to_postgres.py --force
```

---

## Performance

Expected performance matches v2.2.4-beta:

| Metric | Value |
|--------|-------|
| Search accuracy | 88.5% |
| Query latency | ~284ms |
| Indexing speed | ~10 docs/sec |

PostgreSQL adds minimal overhead while providing durability guarantees.

---

## Related Documentation

### Postmortems

These postmortems document critical issues discovered during v2.x development:

- [Vectorlite HNSW Postmortem](../postmortem-vectorlite-hnsw-complete.md) - All 5 HNSW bugs fixed in v2.2.4-beta (data loss, accuracy regression, concurrency issues)
- [Query Accuracy Investigation](../postmortem-query-accuracy-investigation.md) - How we improved from 61.5% to 88.5% accuracy

### Deprecated Versions

| Version | Issue | Recommendation |
|---------|-------|----------------|
| v2.2.0-beta | Critical HNSW data loss | Skip |
| v2.2.1 | Accuracy regression (55%) | Skip |
| v2.2.2 | Partial fixes only | Skip |

**If you're on any of these versions, upgrade directly to v2.3.0-beta.**

---

## Full Changelog

See [CHANGELOG.md](../../CHANGELOG.md) for complete version history.
