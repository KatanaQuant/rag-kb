# Port configuration (only needed if 8000 is taken)
# RAG_PORT=8001

# Resource limits (adjust based on your hardware)
# MAX_CPUS=6.0          # Docker CPU limit
# MAX_MEMORY=10G        # Docker memory limit

# Concurrent processing (embedding + chunking pipeline)
# Higher values = faster processing but more CPU/memory usage
# CHUNK_WORKERS=1                  # Concurrent chunking threads (default: 1, increase for large PDFs)
# EMBEDDING_WORKERS=3              # Concurrent embedding threads
# MAX_PENDING_EMBEDDINGS=6         # Max queued embeddings (recommended: 2x workers)
# Guidelines: 2-4 cores: 2 workers, 6-8 cores: 4 workers, 12+ cores: 6-8 workers
# Note: Set CHUNK_WORKERS=2 if processing many large PDFs with OCR

# Model configuration (optional, uncomment to change)
# Default: sentence-transformers/all-MiniLM-L6-v2 (384 dim, fastest)
# MODEL_NAME=sentence-transformers/all-MiniLM-L6-v2

# Advanced embedding models (better quality, slower inference):
# MODEL_NAME=Snowflake/snowflake-arctic-embed-l-v2.0  # 1024 dim, best quality
# MODEL_NAME=Snowflake/snowflake-arctic-embed-m-v2.0  # 768 dim, balanced
# MODEL_NAME=BAAI/bge-large-en-v1.5                   # 1024 dim, excellent
# MODEL_NAME=BAAI/bge-base-en-v1.5                    # 768 dim, good

# Note: Changing models requires re-indexing (docker-compose down, rm data/knowledge_base.db, docker-compose up)

# File watcher configuration (auto-sync new/modified documents)
# WATCH_ENABLED=true                  # Enable/disable automatic file watching
# WATCH_DEBOUNCE_SECONDS=10.0         # Wait time after last change before indexing
# WATCH_BATCH_SIZE=50                 # Maximum files to index per batch

# Query cache configuration (improves repeat query performance)
# CACHE_ENABLED=true                  # Enable/disable query result caching
# CACHE_MAX_SIZE=100                  # Maximum number of cached queries

# Resumable processing configuration (handles interruptions gracefully)
# RESUMABLE_PROCESSING=true           # Enable/disable resumable processing
# PROCESSING_BATCH_SIZE=50            # Chunks processed before progress checkpoint
# PROCESSING_MAX_RETRIES=3            # Maximum retries for failed files
# CLEANUP_COMPLETED_PROGRESS=false    # Delete completed progress records

# Docling PDF extraction (advanced PDF parsing with layout preservation)
USE_DOCLING=true                      # Enable/disable Docling (falls back to pypdf if false)
# Note: Docling configured for CPU processing with OCR and table extraction enabled
# Note: First run downloads models to .cache/ (persisted between restarts)

# Semantic chunking configuration (intelligent document-aware chunking)
SEMANTIC_CHUNKING=true                # Use Docling HierarchicalChunker for semantic chunks (vs fixed-size)
CHUNK_MAX_TOKENS=512                  # Maximum tokens per semantic chunk
# Note: Semantic chunking preserves document structure (paragraphs, sections, tables)
# Note: Requires USE_DOCLING=true, falls back to fixed-size if disabled
