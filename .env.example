# =============================================================================
# RAG-KB Configuration
# =============================================================================
# This is the ONLY file you should edit for customization.
# Copy this to .env and uncomment/modify the settings you need.
#
# Configuration precedence:
#   1. .env (this file) - YOUR customizations
#   2. docker-compose.yml - Factory defaults (don't edit unless adding features)
#
# After editing: docker-compose restart rag-api
# =============================================================================

# -----------------------------------------------------------------------------
# RESOURCE LIMITS (adjust based on your hardware)
# -----------------------------------------------------------------------------
# Detect your hardware: echo "CPU: $(nproc), RAM: $(free -g | awk '/^Mem:/{print $2}')GB"
#
# Balanced profile (50-60%): Good for multitasking
# MAX_CPUS=4.0          # 50% of 8 cores
# MAX_MEMORY=8G         # 60% of 13GB
#
# Performance profile (70-80%): Fast indexing, less responsive system
# MAX_CPUS=6.0          # 75% of 8 cores
# MAX_MEMORY=10G        # 80% of 13GB

# -----------------------------------------------------------------------------
# PORT CONFIGURATION
# -----------------------------------------------------------------------------
# RAG_PORT=8000         # Change if port 8000 is in use

# -----------------------------------------------------------------------------
# EMBEDDING MODEL
# -----------------------------------------------------------------------------
# Default: Snowflake Arctic Embed 2.0-L (1024 dim, best quality, multilingual)
# MODEL_NAME=Snowflake/snowflake-arctic-embed-l-v2.0
#
# Alternatives:
# MODEL_NAME=sentence-transformers/static-retrieval-mrl-en-v1  # Fast, English-only
# MODEL_NAME=Snowflake/snowflake-arctic-embed-m-v2.0          # Balanced quality/speed
# MODEL_NAME=BAAI/bge-large-en-v1.5                           # Good alternative
# MODEL_NAME=sentence-transformers/all-MiniLM-L6-v2           # Fastest, lowest quality
#
# WARNING: Changing models requires re-indexing!
# docker-compose down && rm data/rag.db && docker-compose up -d

# -----------------------------------------------------------------------------
# CONCURRENT PROCESSING (Pipeline workers)
# -----------------------------------------------------------------------------
# Note: Higher worker counts don't help due to Python GIL contention.
# Use batch encoding instead for real speedups.
#
# EMBEDDING_WORKERS=2         # Keep at 2 (optimal for GIL)
# EMBEDDING_BATCH_SIZE=32     # Chunks per model call (10-50x speedup)
# CHUNK_WORKERS=1             # Single chunker avoids resource contention
#
# Thread parallelism (NumPy/BLAS - releases GIL):
# OMP_NUM_THREADS=2           # OpenMP threads
# MKL_NUM_THREADS=2           # Intel MKL threads

# -----------------------------------------------------------------------------
# BATCH PROCESSING (legacy, for non-pipeline operations)
# -----------------------------------------------------------------------------
# BATCH_SIZE=5                # Files per batch
# BATCH_DELAY=0.5             # Delay between batches (seconds)

# -----------------------------------------------------------------------------
# FILE WATCHER (Auto-sync)
# -----------------------------------------------------------------------------
# WATCH_ENABLED=true                # Enable/disable auto-sync
# WATCH_DEBOUNCE_SECONDS=10.0       # Wait after last change before indexing
# WATCH_BATCH_SIZE=50               # Max files per batch

# -----------------------------------------------------------------------------
# QUERY CACHE
# -----------------------------------------------------------------------------
# CACHE_ENABLED=true          # Enable query result caching
# CACHE_MAX_SIZE=100          # Max cached queries (LRU eviction)

# -----------------------------------------------------------------------------
# DOCUMENT PROCESSING (Docling)
# -----------------------------------------------------------------------------
# USE_DOCLING=true            # Required for PDF/DOCX/EPUB processing
# SEMANTIC_CHUNKING=true      # Use HybridChunker for semantic chunks
# CHUNK_MAX_TOKENS=512        # Max tokens per semantic chunk

# -----------------------------------------------------------------------------
# RESUMABLE PROCESSING
# -----------------------------------------------------------------------------
# RESUMABLE_PROCESSING=true         # Handle interruptions gracefully
# PROCESSING_BATCH_SIZE=50          # Chunks before progress checkpoint
# PROCESSING_MAX_RETRIES=3          # Max retries for failed files
# CLEANUP_COMPLETED_PROGRESS=false  # Delete completed progress records

# -----------------------------------------------------------------------------
# SECURITY: File Type Validation
# -----------------------------------------------------------------------------
# Detects executables masquerading as documents (security feature)
# FILE_TYPE_VALIDATION_ENABLED=true   # Enable validation
# FILE_TYPE_VALIDATION_ACTION=reject  # reject|warn|skip

# -----------------------------------------------------------------------------
# SECURITY: Malware Detection
# -----------------------------------------------------------------------------
# CLAMAV_ENABLED=true                 # ClamAV virus scanning
# HASH_BLACKLIST_ENABLED=true         # Known malware hash detection
# YARA_ENABLED=true                   # YARA rule matching

# -----------------------------------------------------------------------------
# KNOWLEDGE BASE PATH (optional)
# -----------------------------------------------------------------------------
# Default: ./knowledge_base/ (mounted in Docker)
# For custom paths, also update docker-compose.yml volumes
#
# KNOWLEDGE_BASE_PATH=/media/external_drive/documents
# KNOWLEDGE_BASE_PATH=~/my_knowledge_base
# KNOWLEDGE_BASE_PATH=/mnt/nas/knowledge_base
