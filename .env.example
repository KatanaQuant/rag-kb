# Port configuration (only needed if 8000 is taken)
# RAG_PORT=8001

# Model configuration (optional, uncomment to change)
# Default: sentence-transformers/all-MiniLM-L6-v2 (384 dim, fastest)
# MODEL_NAME=sentence-transformers/all-MiniLM-L6-v2

# Advanced embedding models (better quality, slower inference):
# MODEL_NAME=Snowflake/snowflake-arctic-embed-l-v2.0  # 1024 dim, best quality
# MODEL_NAME=Snowflake/snowflake-arctic-embed-m-v2.0  # 768 dim, balanced
# MODEL_NAME=BAAI/bge-large-en-v1.5                   # 1024 dim, excellent
# MODEL_NAME=BAAI/bge-base-en-v1.5                    # 768 dim, good

# Note: Changing models requires re-indexing (docker-compose down, rm data/knowledge_base.db, docker-compose up)

# File watcher configuration (auto-sync new/modified documents)
# WATCH_ENABLED=true                  # Enable/disable automatic file watching
# WATCH_DEBOUNCE_SECONDS=10.0         # Wait time after last change before indexing
# WATCH_BATCH_SIZE=50                 # Maximum files to index per batch

# Query cache configuration (improves repeat query performance)
# CACHE_ENABLED=true                  # Enable/disable query result caching
# CACHE_MAX_SIZE=100                  # Maximum number of cached queries
